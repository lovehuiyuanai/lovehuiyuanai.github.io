[{"title":"2024年的一些计划","url":"/2024/03/09/2024%E5%B9%B4%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%A1%E5%88%92/","content":"<h1 id=\"XIKO\"><a href=\"#XIKO\" class=\"headerlink\" title=\"XIKO\"></a>XIKO</h1><p>正如你所见，XIKO</p>\n","tags":["计划"]},{"title":"ChatGLM的CPU推理方案","url":"/2023/08/20/ChatGLM%E7%9A%84CPU%E6%8E%A8%E7%90%86%E6%96%B9%E6%A1%88/","content":"<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> transformers <span class=\"keyword\">import</span> AutoTokenizer, AutoModel</span><br><span class=\"line\">tokenizer = AutoTokenizer.from_pretrained(<span class=\"string\">&quot;THUDM/chatglm2-6b-int4&quot;</span>, trust_remote_code=<span class=\"literal\">True</span>)</span><br><span class=\"line\">model = AutoModel.from_pretrained(<span class=\"string\">&quot;THUDM/chatglm2-6b-int4&quot;</span>, trust_remote_code=<span class=\"literal\">True</span>).half().<span class=\"built_in\">float</span>()</span><br><span class=\"line\">model = model.<span class=\"built_in\">eval</span>()</span><br><span class=\"line\">response, history = model.chat(tokenizer, <span class=\"string\">&quot;写一首赞美雪的现代诗&quot;</span>, history=[])</span><br><span class=\"line\"><span class=\"built_in\">print</span>(response)</span><br></pre></td></tr></table></figure>\n"},{"title":"NEW","url":"/2023/07/23/NEW/","content":""},{"title":"XIKOTODAY正式启用python后端","url":"/2024/03/24/XIKOTODAY%E6%AD%A3%E5%BC%8F%E5%90%AF%E7%94%A8python%E5%90%8E%E7%AB%AF/","content":"<p>哈哈哈哈……</p>\n<p>我真是服了我自己了，两个文件夹的urls写成一个去了，反复导入</p>\n<p>Django:大哥，你这怎么重复导入urls文件啊</p>\n<p>我:什么？***！</p>\n<p>总之以后注意吧</p>\n","tags":["开发小趣事"]},{"title":"XIKO技术开发路线确定","url":"/2024/02/02/XIKO%E6%8A%80%E6%9C%AF%E5%BC%80%E5%8F%91%E8%B7%AF%E7%BA%BF%E7%A1%AE%E5%AE%9A/","content":"<p>XIKO：为青少年最后的秘密而战！</p>\n<span id=\"more\"></span>\n<p>XIKO前端正式确定使用HTML、CSS开发，后端采用C++开发，数据库使用json文件。服务器正式确定使用Linux操作系统<br>Q&amp;A<br>Q：为什么使用C++作为后端开发语言？<br>A：因为XIKO立项时我只会C++，学习Js太耗时间了，我计划继续精进C++，尽快搞定后端系统。</p>\n<p>Q：XIKO后续会继续研发Js后端与传统数据库架构系统吗？<br>A：XIKO在V1.0.6版本会更新Js后端版本，OpenXIKO在V1.1.1版本会加入对Js后端的支持。数据库系统XIKO暂时没有更新计划（数据库不符合XIKO对于简洁之上的理念）。</p>\n<p>（附XIKO更新计划表）<br>2024.2.15 完成XIKO V1.0.0版本C++后端开发。<br>2024.2.16 完成XIKO V1.0.0版本HTML前端开发。<br>2024.7.20 完成XIKO服务器测试。<br>2024.8.11 完成OpenXIKO V1.0.0版本上线Github、Gitee。</p>\n<p>XIKO V1.0.0 完成基本轻量论坛系统开发。<br>XIKO V1.0.2 对XIKO移动网页端支持。<br>XIKO V1.0.4 对XIKO页面进行更新，做到美观与简洁的提升。<br>XIKO V1.0.6 XIKO后端支持Js，方便后期项目接手。</p>\n<p>OpenXIKO V1.0.0 正式发布XIKO开源版本。<br>OpenXIKO V1.0.6 与Xiko V1.0.2更新对齐。<br>OpenXIKO V1.0.7 继续完成OpenXIKO API对齐编写。<br>OpenXIKO V1.1.1 与XIKO V1.0.6更新对齐。<br>……<br>后续开发将持续公开。</p>\n<p>Q：XIKO还会开发哪些配套产品？<br>A：平方云系统，保证XIKO产品信息传递安全，提升用户体验。喵的书架，是一个小说发布网站。喵的日记，从用户开始编写日记到服务器保存日记全程采用高安全性算法，让用户的隐私不再是纸上谈兵。XIKOGPT，XIKO的ai大模型产品，目前还不能公布太多消息，敬请期待！</p>\n<p>Q：XIKO平台有类似小天才的内容审核机制吗？<br>A：XIKO平台只会对于极端、色情、暴力、人身攻击的不良言论进行查封，尽可能保证用户的观点自由。</p>\n","tags":["OpenXIKO"]},{"title":"OpenXiko介绍文档","url":"/2023/01/28/blog/","content":"<div class=\"hbe hbe-container\" id=\"hexo-blog-encrypt\" data-wpm=\"Oh, this is an invalid password. Check and try again, please.\" data-whm=\"OOPS, these decrypted content may changed, but you can still have a look.\">\n  <script id=\"hbeData\" type=\"hbeData\" data-hmacdigest=\"9caa2a154b01a2d479ab3b1539d499e62ab43e877e93d52d2e2f0938eaacc488\">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</script>\n  <div class=\"hbe hbe-content\">\n    <div class=\"hbe hbe-input hbe-input-default\">\n      <input class=\"hbe hbe-input-field hbe-input-field-default\" type=\"password\" id=\"hbePass\">\n      <label class=\"hbe hbe-input-label hbe-input-label-default\" for=\"hbePass\">\n        <span class=\"hbe hbe-input-label-content hbe-input-label-content-default\">Hey, password is required here.</span>\n      </label>\n    </div>\n  </div>\n</div>\n<script data-pjax src=\"/lib/hbe.js\"></script><link href=\"/css/hbe.style.css\" rel=\"stylesheet\" type=\"text/css\">","tags":["小胡的开源项目"]},{"title":"test_my_site","url":"/2023/07/21/test-my-site/","content":""},{"title":"world","url":"/2023/07/14/world-1/","content":""},{"title":"world","url":"/2023/07/22/world/","content":""},{"title":"一些思考","url":"/2023/08/14/%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/","content":"<p>人的大脑运作，可以看作是一个函数系统，每个函数，都对应一个输入，产生一个输出。</p>\n<span id=\"more\"></span>\n<p>如果按照这个原理，编写一个用于批量处理此类函数的机器学习程序，不是几句可以仿照人脑进行思考了吗？由此，我决定在此宣布，仿人类数字系统计划，即ADSP，正式启动！我将在此Blog中一直不断更新。</p>\n"},{"title":"下学期计划来咯","url":"/2024/02/17/%E4%B8%8B%E5%AD%A6%E6%9C%9F%E8%AE%A1%E5%88%92%E6%9D%A5%E5%92%AF/","content":"<p>最近快开学了，啊计划也该定一定了。</p>\n<span id=\"more\"></span>\n<p>首先，基于nanoGPT的代码，搞出ZERO-0.5、ZERO-0.5-Chat、ZERO-0.5-Code三个达到10亿参数的模型</p>\n"},{"title":"中文测试一","url":"/2023/08/14/%E4%B8%AD%E6%96%87%E6%B5%8B%E8%AF%95%E4%B8%80/","content":""},{"title":"丸仔","url":"/2023/08/23/%E4%B8%B8%E4%BB%94/","content":"<p>        我家有一只猫，名为丸仔。全身是黑白相间的，有一对尖尖的耳朵，和一双圆溜溜的眼睛，走起路来总爱翘着尾巴，昂着头，就像一位大爷似的。要说起它最喜欢的事，不外乎睡觉与</p>\n<p>        我非常喜欢跟它玩，可它好像总不领情似的，就是不愿意搭理我。于是我找了根绳子，放到餐桌上，将粗粗的绳头放下去逗它。第一次我抖了抖绳头，它没理我。于是我加大幅度，像旋风似的抖动绳头，这下，它可能是觉得很新奇，就走了过来，好奇地去用爪子碰了碰绳头。这时我一抖，吓得它缩回了爪子，往后退了几步。于是我放慢动作，轻轻抖动，它便放心大胆地走了过来。这次它先目不睛地盯着绳头，突然猛地扑了过去，想咬住绳头。说时迟，那时快，我猛一抽绳，它便扑了空。我暗自得意，心想：大家都说猫动作快，今天可输在我手里了。可还没等我这高兴劲过去，便觉得手里的绳子沉了许多，我朝下一看，只见它已经死死咬住绳头。我想把绳头从它嘴里拉出来，可是却把它经拉上来了。我想万一它松口摔下去，那可不得了，所以我只好认输了，把整条绳子放了下去。</p>\n<p>        这次我玩得真开心，下次我得用另一种方法让它陪我玩。</p>\n","tags":["小胡的小文"]},{"title":"写小说机器人","url":"/2023/09/10/%E5%86%99%E5%B0%8F%E8%AF%B4%E6%9C%BA%E5%99%A8%E4%BA%BA/","content":"<p>胡哲涵最新开源项目，小说大师python源码</p>\n<span id=\"more\"></span>\n<figure class=\"highlight markdown\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"code\">                                                          声明</span></span><br><span class=\"line\"><span class=\"code\">本项目基于pytorch实现。可以自行更换训练文本，但请记住：训练文本一定一定得是TXT格式！！！</span></span><br><span class=\"line\"><span class=\"code\">另外，本项目仅用作学习交流，严禁用于商用、参加任何形式以及团体组织的比赛，请使用者严格遵守Apache License Version 开源协议</span></span><br><span class=\"line\"><span class=\"code\">作者不承担此程序造成的一切后果与责任。</span></span><br><span class=\"line\"><span class=\"code\">版权归作者重庆市小学生胡哲涵所有，Github likehuiyuanai。</span></span><br><span class=\"line\"><span class=\"code\">PS：最近喜欢看某科学的超电磁炮，所以实例代码用的是日本轻小说《魔法禁书目录》作为训练数据，暂拒绝公开此数据集（你可以自己整理，字数多亿些训练效果好点</span></span><br><span class=\"line\"><span class=\"code\">本博客（帖子）的版权也同样归胡哲涵所有，严禁转发或参加比赛！</span></span><br><span class=\"line\"><span class=\"code\">低调！低调！低调！</span></span><br></pre></td></tr></table></figure>\n<p>正式开始（暂时没有开发代码生成器的意向，毕竟我不喜欢。没有bug的代码等同于人失去了灵魂！）</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">from</span> scipy.sparse <span class=\"keyword\">import</span> csr_matrix</span><br><span class=\"line\"><span class=\"keyword\">from</span> tensorboardX <span class=\"keyword\">import</span> SummaryWriter</span><br><span class=\"line\">%matplotlib inline</span><br></pre></td></tr></table></figure>\n<p>导入库，幼儿园都学过吧。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">with</span> <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;./mfjsml.txt&#x27;</span>, <span class=\"string\">&#x27;r&#x27;</span>, encoding=<span class=\"string\">&#x27;utf-8&#x27;</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">    data = f.readlines()</span><br></pre></td></tr></table></figure>\n<p>读取数据集，mfjsml这个名字可以改，但数据集和jupyter lab代码放一个文件夹下！</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">data=<span class=\"string\">&#x27;&#x27;</span>.join(data)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(data[:<span class=\"number\">100</span>])</span><br></pre></td></tr></table></figure>\n<p>展示数据集的一部分</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">chars = <span class=\"built_in\">list</span>(<span class=\"built_in\">set</span>(data))</span><br><span class=\"line\">data_size, vocab_size = <span class=\"built_in\">len</span>(data), <span class=\"built_in\">len</span>(chars)</span><br><span class=\"line\"><span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;data has <span class=\"subst\">&#123;data_size&#125;</span> characters, <span class=\"subst\">&#123;vocab_size&#125;</span> unique.&#x27;</span>)</span><br><span class=\"line\">char_to_ix = &#123; ch:i <span class=\"keyword\">for</span> i,ch <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(chars) &#125;</span><br><span class=\"line\">ix_to_char = &#123; i:ch <span class=\"keyword\">for</span> i,ch <span class=\"keyword\">in</span> <span class=\"built_in\">enumerate</span>(chars) &#125;</span><br></pre></td></tr></table></figure>\n<p>接下来我们开始构建LSTM模型</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">X_train = csr_matrix((<span class=\"built_in\">len</span>(data), <span class=\"built_in\">len</span>(chars)), dtype=np.<span class=\"built_in\">int</span>)</span><br><span class=\"line\">char_id = np.array([chars.index(c) <span class=\"keyword\">for</span> c <span class=\"keyword\">in</span> data])</span><br><span class=\"line\">X_train[np.arange(<span class=\"built_in\">len</span>(data)), char_id] = <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">y_train = np.roll(char_id,-<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">X_train.shape</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">y_train.shape</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">get_batch</span>(<span class=\"params\">X_train, y_train, seq_length</span>):</span><br><span class=\"line\">    X = X_train</span><br><span class=\"line\">    <span class=\"comment\">#X = torch.from_numpy(X_train).float()</span></span><br><span class=\"line\">    y = torch.from_numpy(y_train).long()</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">0</span>, <span class=\"built_in\">len</span>(y), seq_length):   </span><br><span class=\"line\">        id_stop = i+seq_length <span class=\"keyword\">if</span> i+seq_length &lt; <span class=\"built_in\">len</span>(y) <span class=\"keyword\">else</span> <span class=\"built_in\">len</span>(y)</span><br><span class=\"line\">        <span class=\"keyword\">yield</span>([torch.from_numpy(X[i:id_stop].toarray().astype(np.float32)), </span><br><span class=\"line\">               y[i:id_stop]])</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">sample_chars</span>(<span class=\"params\">rnn, X_seed, h_prev, length=<span class=\"number\">20</span></span>):</span><br><span class=\"line\">    <span class=\"string\">&#x27;&#x27;&#x27;Generate text using trained model&#x27;&#x27;&#x27;</span></span><br><span class=\"line\">    X_next = X_seed</span><br><span class=\"line\">    results = []</span><br><span class=\"line\">    <span class=\"keyword\">with</span> torch.no_grad():</span><br><span class=\"line\">        <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(length):        </span><br><span class=\"line\">            y_score, h_prev = rnn(X_next.view(<span class=\"number\">1</span>,<span class=\"number\">1</span>,-<span class=\"number\">1</span>), h_prev)</span><br><span class=\"line\">            y_prob = nn.Softmax(<span class=\"number\">0</span>)(y_score.view(-<span class=\"number\">1</span>)).detach().numpy()</span><br><span class=\"line\">            y_pred = np.random.choice(chars,<span class=\"number\">1</span>, p=y_prob).item()</span><br><span class=\"line\">            results.append(y_pred)</span><br><span class=\"line\">            X_next = torch.zeros_like(X_seed)</span><br><span class=\"line\">            X_next[chars.index(y_pred)] = <span class=\"number\">1</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"string\">&#x27;&#x27;</span>.join(results)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">class</span> <span class=\"title class_\">nn_LSTM</span>(nn.Module):</span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">__init__</span>(<span class=\"params\">self, input_size, hidden_size, output_size</span>):</span><br><span class=\"line\">        <span class=\"built_in\">super</span>().__init__()</span><br><span class=\"line\">        self.hidden_size = hidden_size</span><br><span class=\"line\">        self.lstm = nn.LSTM(input_size, hidden_size)</span><br><span class=\"line\">        self.out = nn.Linear(hidden_size, output_size)</span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">forward</span>(<span class=\"params\">self, X, hidden</span>):</span><br><span class=\"line\">        _, hidden = self.lstm(X, hidden)</span><br><span class=\"line\">        output = self.out(hidden[<span class=\"number\">0</span>])</span><br><span class=\"line\">        <span class=\"keyword\">return</span> output, hidden</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">def</span> <span class=\"title function_\">initHidden</span>(<span class=\"params\">self</span>):</span><br><span class=\"line\">        <span class=\"keyword\">return</span> (torch.zeros(<span class=\"number\">1</span>, <span class=\"number\">1</span>, self.hidden_size),</span><br><span class=\"line\">                torch.zeros(<span class=\"number\">1</span>, <span class=\"number\">1</span>, self.hidden_size)</span><br><span class=\"line\">               )</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">hidden_size = <span class=\"number\">256</span></span><br><span class=\"line\">seq_length = <span class=\"number\">25</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">rnn = nn_LSTM(vocab_size, hidden_size, vocab_size)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">loss_fn = nn.CrossEntropyLoss()</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">optimizer = torch.optim.Adam(rnn.parameters(), lr=<span class=\"number\">0.005</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">def</span> <span class=\"title function_\">train</span>(<span class=\"params\">X_batch, y_batch</span>):</span><br><span class=\"line\">    h_prev = rnn.initHidden()</span><br><span class=\"line\">    optimizer.zero_grad()</span><br><span class=\"line\">    batch_loss = torch.tensor(<span class=\"number\">0</span>, dtype=torch.<span class=\"built_in\">float</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"built_in\">len</span>(X_batch)):</span><br><span class=\"line\">        y_score, h_prev = rnn(X_batch[i].view(<span class=\"number\">1</span>,<span class=\"number\">1</span>,-<span class=\"number\">1</span>), h_prev)</span><br><span class=\"line\">        loss = loss_fn(y_score.view(<span class=\"number\">1</span>,-<span class=\"number\">1</span>), y_batch[i].view(<span class=\"number\">1</span>))</span><br><span class=\"line\">        batch_loss += loss</span><br><span class=\"line\">    batch_loss.backward()</span><br><span class=\"line\">    optimizer.step()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> y_score, batch_loss/<span class=\"built_in\">len</span>(X_batch)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">writer = SummaryWriter(<span class=\"string\">f&#x27;logs/lstm1_<span class=\"subst\">&#123;time.strftime(<span class=\"string\">&quot;%Y%m%d-%H%M%S&quot;</span>)&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<p>准备好了吗？所有CUDA&#x2F;Tensor核心全部启动启动还有这个，启动训练！</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">all_losses = []</span><br><span class=\"line\">print_every = <span class=\"number\">100</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">20</span>):    </span><br><span class=\"line\">    <span class=\"keyword\">for</span> batch <span class=\"keyword\">in</span> get_batch(X_train, y_train, seq_length):</span><br><span class=\"line\">        X_batch, y_batch = batch</span><br><span class=\"line\">        _, batch_loss = train(X_batch, y_batch)</span><br><span class=\"line\">        all_losses.append(batch_loss.item())</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(all_losses)%print_every==<span class=\"number\">1</span>:</span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">f&#x27;----\\n训练正在进行，请耐心等待 Loss:<span class=\"subst\">&#123;np.mean(all_losses[-print_every:])&#125;</span> at iter: <span class=\"subst\">&#123;<span class=\"built_in\">len</span>(all_losses)&#125;</span>\\n----&#x27;</span>)</span><br><span class=\"line\">            <span class=\"comment\"># log to tensorboard every X iterations. Can be removed if Tensorboard is not installed.</span></span><br><span class=\"line\">            writer.add_scalar(<span class=\"string\">&#x27;loss&#x27;</span>, np.mean(all_losses[-<span class=\"number\">100</span>:]), <span class=\"built_in\">len</span>(all_losses))</span><br><span class=\"line\">            <span class=\"comment\"># generate text every X iterations</span></span><br><span class=\"line\">            <span class=\"built_in\">print</span>(sample_chars(rnn, X_batch[<span class=\"number\">0</span>], rnn.initHidden(), <span class=\"number\">200</span>))</span><br></pre></td></tr></table></figure>\n<p>终于可以启动生成器了</p>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">print</span>(sample_chars(rnn, X_batch[<span class=\"number\">20</span>], rnn.initHidden(), <span class=\"number\">200</span>))</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\">torch.save(rnn.state_dict(), <span class=\"string\">&#x27;one.pth&#x27;</span>)</span><br></pre></td></tr></table></figure>\n<p>把模型存着。你自己训练的模型你自己可以随便搞，作者对此没有版权和责任<br>另外，推荐大家去看看某科学的超电磁炮，特别好看！要联系的去我的主页加我邮箱</p>\n"},{"title":"加密博客，仅发布者可以访问","url":"/2023/09/07/%E5%8A%A0%E5%AF%86%E5%8D%9A%E5%AE%A2%EF%BC%8C%E4%BB%85%E5%8F%91%E5%B8%83%E8%80%85%E5%8F%AF%E4%BB%A5%E8%AE%BF%E9%97%AE/","content":"<div class=\"hbe hbe-container\" id=\"hexo-blog-encrypt\" data-wpm=\"Oh, this is an invalid password. Check and try again, please.\" data-whm=\"OOPS, these decrypted content may changed, but you can still have a look.\">\n  <script id=\"hbeData\" type=\"hbeData\" data-hmacdigest=\"fac2f243a6927c1bde5d4ac2751d8c0be979eed0942cf9d2032f11b5a2ce504a\">fae7d0b5377b9f6c290dcd8adf41b25381416438debc227eee11d0ec2314c232463928add14c62c788a24a18da5f5941753b30bc6525f02b6b098ce6a14c253da62f446c0609b22536c687c48d510515bdc5b56bb459aeab00d93b516ce93ed711045decc7eff2e2e351339ef72c66a18f78cf6ee2352e5d6ffe06a94eab4ee143193b64ca0b82ae52a67dabe88d5444f42fd00de8b4c5b8b1a56a04fda6b8a8e067269b1dfad1cd028d4fd145306515</script>\n  <div class=\"hbe hbe-content\">\n    <div class=\"hbe hbe-input hbe-input-default\">\n      <input class=\"hbe hbe-input-field hbe-input-field-default\" type=\"password\" id=\"hbePass\">\n      <label class=\"hbe hbe-input-label hbe-input-label-default\" for=\"hbePass\">\n        <span class=\"hbe hbe-input-label-content hbe-input-label-content-default\">Hey, password is required here.</span>\n      </label>\n    </div>\n  </div>\n</div>\n<script data-pjax src=\"/lib/hbe.js\"></script><link href=\"/css/hbe.style.css\" rel=\"stylesheet\" type=\"text/css\">","tags":["加密博客"]},{"title":"我想你了","url":"/2023/08/27/%E6%88%91%E6%83%B3%E4%BD%A0%E4%BA%86/","content":"<p>                                                将它悬于窗畔，</p>\n<p>                                                   观之，细观，</p>\n<p>                                            其在日光下熠熠生辉，</p>\n<p>                                            犹如水晶般剔透无暇，</p>\n<p>                                        恰似你的眸子般明净如水。</p>\n<p>                                                    闻之，倾听，</p>\n<p>                                             它在微风中轻轻摇摆，</p>\n<p>                                              宛如琴音般悠扬动人，</p>\n<p>                                         犹似你的笑声那般欢快宜人。</p>\n<p>                                                此刻，又闻其声，</p>\n<p>                                                    清亮而干脆，</p>\n<p>                                    那是风儿承载着我悄然送达的心语，</p>\n<p>                                            嘘，请静静的听吧，</p>\n<p>                                                那清脆的声响，</p>\n<p>                                            每个音节都在诉说，</p>\n<p>                                                    我想你了。</p>\n","tags":["小胡的小文"]},{"title":"新主题代码块测试","url":"/2024/02/19/%E6%96%B0%E4%B8%BB%E9%A2%98%E4%BB%A3%E7%A0%81%E5%9D%97%E6%B5%8B%E8%AF%95/","content":"<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> tensorflow <span class=\"keyword\">as</span> tf</span><br><span class=\"line\"></span><br><span class=\"line\">mnist = tf.keras.datasets.mnist</span><br><span class=\"line\"></span><br><span class=\"line\">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class=\"line\">x_train, x_test = x_train / <span class=\"number\">255.0</span>, x_test / <span class=\"number\">255.0</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">model = tf.keras.models.Sequential([</span><br><span class=\"line\">  tf.keras.layers.Flatten(input_shape=(<span class=\"number\">28</span>, <span class=\"number\">28</span>)),</span><br><span class=\"line\">  tf.keras.layers.Dense(<span class=\"number\">128</span>, activation=<span class=\"string\">&#x27;relu&#x27;</span>),</span><br><span class=\"line\">  tf.keras.layers.Dropout(<span class=\"number\">0.2</span>),</span><br><span class=\"line\">  tf.keras.layers.Dense(<span class=\"number\">10</span>, activation=<span class=\"string\">&#x27;softmax&#x27;</span>)</span><br><span class=\"line\">])</span><br><span class=\"line\"></span><br><span class=\"line\">model.<span class=\"built_in\">compile</span>(optimizer=<span class=\"string\">&#x27;adam&#x27;</span>,loss=<span class=\"string\">&#x27;sparse_categorical_crossentropy&#x27;</span>,metrics=[<span class=\"string\">&#x27;accuracy&#x27;</span>])</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">model.fit(x_train, y_train, epochs=<span class=\"number\">10</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">model.evaluate(x_test,  y_test, verbose=<span class=\"number\">2</span>)</span><br></pre></td></tr></table></figure>"},{"title":"物理定律","url":"/2023/08/08/%E7%89%A9%E7%90%86%E5%AE%9A%E5%BE%8B/","content":"<p>        有本书上说：“一个面所受的压力等于垂直压在桌面上的物体的重力。”我不懂，并非是真的不知道，而是并不确信那个面到底能承受多大的压力。</p>\n<p>        曾几何时，耳边不再是风的鸣声，而是家长的唠叨声、骂声。眼前也早已不是樱花飞舞，而是家长着急的面庞。</p>\n<p>        回过神来，我走在落叶飞舞的路上。</p>\n<p>        果然，满地落叶覆盖了大半边路。这里好久没有人来了，也只有我这样的清闲之士才会有如此雅兴来此一聚。几片枯黄的叶子垂挂在树枝上显得格外单调。凉风忽起，地上的叶子打着旋儿肆意的欢闹着，树上的几片树叶也飘然落下，一片，两片……我数着数着竟数不清了。</p>\n<p>        我一直以为只有我是爱落叶的，因为我和它们一样都没有压力似的，在那个充满压力的秋天尽情飞舞。而别人，很少有人甚至没人会像我一样如此清闲。似乎来年的六月是为别人而降临的，而外界所施加的力也只是针对别人的。我是一个特殊的人，尽管外界的温度再怎么升高，我还是保持在零度。那本书上告诉我说：“物理学上把冰水混合物的温度规定为0摄氏度”，我想我就是。</p>\n<p>        一片落叶猛然间落在我的头上，但它并未逗留，仿佛落叶归根是它永远的归宿，除此之外的任何地方都不是它的栖身之地。所以我做了一个在别人看来似乎很傻的举动。我把一片片落叶堆积在一起埋在树下，因为他们是有使命的，我要帮他们完成。他们也是有压力的，只不过它们在尽力伪装罢了。但外界的因素并没有阻挡它们过冬，它们依然要面对寒冷的冬天，只不过是换了一个位置罢了。它们把压力转化为动力，待到明年春天来临的时候再一并迸发出来。</p>\n<p>        或许，我也应该这样吧。</p>\n","tags":["小胡的小文"]},{"title":"桌子与椅子","url":"/2023/08/02/%E6%A1%8C%E5%AD%90%E4%B8%8E%E6%A4%85%E5%AD%90/","content":"<p>​        随着放学铃声慢慢的回荡，。劳累了一天的黑板和桌子都相继入睡了。只有椅子还不想休息。自诞生以来，他就有许多想不通的事情，比如，为什么自己只配在人们的屁股底下呆着？他想了很久，在他思考的期间，大约有十届学生都相继离去了。但是，他还是想不明白。</p>\n<p>​       “喂兄弟！”椅子说。</p>\n<p>​       “干哈呀？”桌子迷迷糊糊的问道。</p>\n<p>​\t“咱们聊会儿吧，我睡不着。”</p>\n<p>​\t“你数羊吧，一只羊、两只羊……或者，你可以数学生，一个学生、两个学生……”说着说着，桌子又要昏昏睡去了。</p>\n<p>​\t“快醒醒啊！我一直想问你个问题：你在我上面这么多年，觉得我怎么样？”</p>\n<p>​\t“咱们一起待了60多年来，我可以负责的告诉你，你绝对是我最好的兄弟。”桌子老实的说。</p>\n<p>​\t“那为什么你总要抢我风头？”</p>\n<p>​\t“不是的。”桌子被这突如其来的问题问的语无伦次。</p>\n<p>​\t“不是个屁，凭什么那些学生对你鞠躬，非得把屁股对着我？尤其是那个小孩，天天放屁熏得我都要吐了！”</p>\n<p>​\t“够了。你不就是嫌我吗？那你可以走呀！再说那个小孩放的屁我不是也被熏着了吗？”</p>\n<p>​\t“好，我走。”</p>\n<p>​\t从那以后，学校里少了一张椅子，一张自卑的椅子。</p>\n","tags":["小胡的小文"]},{"title":"无题","url":"/2023/08/04/%E6%97%A0%E9%A2%98/","content":"<p>        明媚的阳光笼罩着一只断了弦的风筝，载着美好的心情，飘了，飞了，自由了。</p>\n<p>                                                                                                        ——题记</p>\n<p>        快乐情。</p>\n<p>        窗外的雨淅沥沥的下着，天空流泪了，泪水冲刷着树叶，拍打着窗户，大地上淌着水，写着一首欢乐的歌，天空终于止住了笑之泪，彩虹便迫不及待地挂在天边，真漂亮，树叶甩甩水珠，显得更惹眼了，小草伸伸懒腰，换了件绿衣裳，太阳抚摸着他们，有一种慵懒之美。</p>\n<p>        雨止了，风筝飞得更欢快了吧？</p>\n<p>        惬意情</p>\n<p>        海浪抚摸着岩石，轻轻拍打着沙滩，放眼望去是望不到边的海洋。在纸上写下烦恼，折成纸船抛入海里，让船载着愁飘走吧。静静的躺在沙滩上让海水没过身体，享受那丝丝爽意带来的惬意心情；静静坐在沙滩上，看太阳升起时的灿烂一刻，享受通红的天边带来诗意的心情，在海边扎个帐篷，看海，看海的朝汐潮落，多美好呀！</p>\n<p>        愁飘了，风筝飞得更惬意了吧？</p>\n<p>        自由情</p>\n<p>        银铃般的笑声在野林中传响，身边的树、草、花每一物都那么美好。土壤依旧默默地散发着芬芳，兔子眼里不再是恐惧，太阳透过树枝散在土地上，形成大大小小的光圈，鸟鸣从头顶上传来，多清脆的交响乐！坐在蓬松的土壤上，给兔子讲一个动听的故事。</p>\n<p>        情好了，风筝飞得更自由了吧？</p>\n<p>        后记</p>\n<p>欢快+惬意+自由&#x3D;好心情。原来好心情就是那么简单。那只断了弦的风筝，应该达到目的了吧？</p>\n","tags":["小胡的小文"]},{"title":"生命的角落","url":"/2023/08/05/%E7%94%9F%E5%91%BD%E7%9A%84%E8%A7%92%E8%90%BD/","content":"<p>        “不要为了追求目的而忽略过程，其实过程及目的。生命便在于这样一个过程，在于每一个细节，需要用一颗心来细细品味。”</p>\n<p>        也许只在于四季平凡的交替中不经意间瞥见的哪一处明媚春光，也许只是在某一天繁忙的工作后家人递来一杯暖入心底的热茗，也许是一份迟来的生日祝福。就是这样简单而平淡，但回想起来，总有一份铭心的感动。</p>\n<p>         每一处熟悉的角落都值得你去留恋。正因为熟悉，便觉得寡淡无味，当某一天，它不再出现在你的视野里，你的心也空了一角，才明白，正是这份熟悉和习惯了它存在你的生命中，源于骨子里的依赖的信念早已在你的心中根深蒂固。平淡中便是最真挚的情感，也需要守候，不要让自己在追求极致精彩的人生路上遗失了那些熟悉的风景，当蓦然回首，孤寂冷旷的风里只剩你孤独一人，是否生命早已冰冷。</p>\n<p>       人的一生中会忽略很多，只是一句普通不过便消散在岁月烟尘中。最简单不过的，人生的幸福就在于活着，可太多的人贪恋着物质上的满足欲，忙忙碌碌间，穷其一生便这么度过，何时曾真正放下身心，与家人聚在一起其乐融融的笑谈家常，独享天伦之乐。很平常，却很快乐，这就是生命的滋味，细细的咀嚼，用心去体味，每个人都不必刻意去追寻，就在身边的幸福，它或许小的不起眼，却大的充满了你的心。很多人不愿承认，对此嗤之以鼻，这不过是他们的苛求，有时候一个笑容远胜你一天所赚的财富。，幸福本就没有定义，不论大小，洋溢着生活的每一处，之所以幸福，就因为那份平凡的滋味，平凡便是熟悉的伟大。</p>\n<p>         “生命是一个列向着一个叫死亡的终点疾驰的火车，沿途有许多美丽的风景值得我们留念”，火车总在不停的行驶着，迎接着新的事物，也许有很多我们曾忘却的旧的记忆，人就是这样，装满又漏去，但总有一样不变的就是你的心，用心去感喟平凡的生活，去唤醒那些潜藏的快乐，生命便在于平凡的过程，平凡里的伟大，平凡中的感动与铭记，这就是生命的滋味。</p>\n","tags":["小胡的小文"]},{"title":"现实中的青春","url":"/2023/08/07/%E7%8E%B0%E5%AE%9E%E4%B8%AD%E7%9A%84%E9%9D%92%E6%98%A5/","content":"<p>        不知从什么时候起我喜欢上了发呆。别人看我呆呆地看着某一处好似十分悠闲，实则是我心里空虚得令人恐慌。</p>\n<p>        走在路上，我总是不时仰头看着天空，之前，我从来都是以为云就固定在那里，哪都不会去。直达现在，我站立仰头时才发现，云真的在太阳得照耀下一点一点地挪移着，好似一列空中的列车，慢慢地向天边驶去，真美啊。然而我心中那美丽的泡沫，还未发出五彩的光芒就开始在烈日下无限膨胀、膨胀，最终消失、消失的无影无踪，尽是那么突然，似乎它从未出现过一样。宛如一场梦魇。我还未从喜悦中醒过来时，它已消失殆尽，留下无尽得虚无。</p>\n<p>        我经常躺在床上，默默地望着璀璨的星空。尽管重庆的夜晚早已被灯火与云朵统治，但我还是仿佛看到了遥遥牛郎星和迢迢织女星跨越咫尺的思念。笑话，这怎么可能是真实的？大概是我看错了吧。世上哪里有真正的爱情，顶多是人们为本我的欲望、为自我的自私编制的绝妙的谎言。或许不那么极端，世上并不是没有真爱，而是人们之间的爱都不够真。这世上慌言太多、就连一个小孩也是从小听着由慌言编织的童话长大，而我未开始就结束的故事又不得不让我认真的对待这个世界。一个由无数混杂编织出的看似正常的世界。在这混杂中，我只能日复一日的重复着机械的动作，把内心压抑在一个孤独的时空里。</p>\n<p>孤独着，终于慌然大悟，也许生命本不该有那么多无所谓的执着，</p>\n<p>一切都应该像歌德说的“我爱你，与你何干？”那样。默默放下已有多年的眼神，或许更好。</p>\n<p>        或许,有些事就是要放下吧。</p>\n","tags":["小胡的小文"]},{"title":"真正的作家","url":"/2023/08/05/%E7%9C%9F%E6%AD%A3%E7%9A%84%E4%BD%9C%E5%AE%B6/","content":"<p>         有两位作家，我一直在读他们的作品，百读不厌。他们二位分别是郑渊洁、秦文君。</p>\n<p>        在这两位作家的书中，并没有太多华丽的词句，人物也很普通。但不管什么时候读，都有一种无法用言语形容的感受。</p>\n<p>        看过郑渊洁写的书的同学们都知道，郑渊洁写的是童话。童话童话，到底是笔下虚幻的事物。虽说如此，但都能使我觉得仿佛处身于书中的世界中。令我更为惊叹的是：郑渊洁已经是大人甚至快到老人了，却还是有如此深厚的理想主义风格。他最让我称奇的本领便是能将最深刻的批判与最天真的文字相结合，让人始终记忆犹新。</p>\n<p>        秦文君的作品我并没读过太多，但我始终都很喜欢《男生贾里全传》，尤其是书友庄静这一章节。虽说秦文君不是男性，但她仍能把贾里纯洁的情愫写得那么传神，可见她对于当下孩子的心理理解之深刻。</p>\n<p>         现实中不缺会背诵整部成语词典的人，不缺能写比喻拟人排比的优生，更不缺能默写整部《唐诗三百首》的天才……但当下，缺少一个真正的作家。</p>\n<p>         真正的作家，不可能是一句话里面用上七八个成语的人。我敢说现在那些日入数万的网文写手用千言万语，仍旧比不上一百年多前那句“不然，那赵家的狗，何以看我两眼呢？”，现在的学生所受的语文教育也不再强调思想的深度了。相比思考问题本质，语文书更喜欢教学生写一些毫无用处的废话。可悲吗？没什么可悲的。深层的思考不可能人人都具有，那样他们的卷子改起来太麻烦了。</p>\n<p>        或许，以后，真正的作家就慢慢在野火中被烧尽了。</p>\n","tags":["小胡的小文"]},{"title":"秋天的美","url":"/2023/08/15/%E7%A7%8B%E5%A4%A9%E7%9A%84%E7%BE%8E/","content":"<p>        秋天的美，在你不注意的时候，跟着秋姑娘的节奏，渐渐来到了人间……</p>\n<p>        秋天的美，是给田野的……</p>\n<p>        田野里金灿灿的稻谷好似一片金色的海洋，雪白的棉花令人恍如置身于白雪的世界。金色的波浪翻滚着，雪白的世界摆动着，这金色凝聚而成的美，是农民们用汗水浇铸成的。</p>\n<p>        秋天的美，是给果园的……</p>\n<p>果园里苹果露出红红的脸蛋，梨子把果树压弯了腰；石榴看见了，笑得咧开了肚皮……这里的美，是沉甸甸的果实之美，是果农用辛勤劳动的劳动摘取的。</p>\n<p>         秋天的美，是给树林的……</p>\n<p>枫叶红似火，白杨叶绿如草，银杏叶黄赛金。它们的叶子仿佛蝴蝶一样，在半空翩翩起舞了好久才落下。这里的美，是植树人用心血凝聚成的。</p>\n<p>秋天，一个充满美丽的季节，一个洋溢着丰收喜悦的季节，一个充满着无限快乐的季节！让我们珍惜秋天，珍惜这个短暂的季节给我们带来的幸福。</p>\n","tags":["小胡的小文"]},{"title":"白开水","url":"/2023/08/17/%E7%99%BD%E5%BC%80%E6%B0%B4/","content":"<p>                                        人生就像一杯白开水，</p>\n<p>                                        刚开始还是淡淡无味。</p>\n<p>                                但渐渐的你就会感到白开水的，</p>\n<p>                                                        甘甜。</p>\n<p>                                    从苦到甜经历过多少艰辛，</p>\n<p>                                               经历过多少坎坷。</p>\n<p>                                                    只要有付出，</p>\n<p>                                                    就会有回报。</p>\n<p>                                                   到最后就会有，</p>\n<p>                                            你所应该拥有的成就。</p>\n<p>                                                    就会有回报。</p>\n","tags":["小胡的小文"]},{"title":"第一个博客","url":"/2023/08/14/%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%8D%9A%E5%AE%A2/","content":"<blockquote>\n<p>这是我发布的基于HEXO的2.0版本博客，稍后我会写出教程</p>\n</blockquote>\n"},{"title":"紫鲸第一、二章","url":"/2023/08/15/%E7%B4%AB%E9%B2%B8%E7%AC%AC%E4%B8%80%E7%AB%A0/","content":"<div class=\"hbe hbe-container\" id=\"hexo-blog-encrypt\" data-wpm=\"Oh, this is an invalid password. Check and try again, please.\" data-whm=\"OOPS, these decrypted content may changed, but you can still have a look.\">\n  <script id=\"hbeData\" type=\"hbeData\" data-hmacdigest=\"75f843456653712d8cb1d41e7364813b35bfa4d4cb723d05d135f5c0e14eaab3\">e79c3f9ca5e39251793a779759b6e1cfba6ca82f8f36e6649bf58bbb055b0ecf275024fd3780581053c4ea289fe147c86e8ef5a33d9a228a9b7301fc5bbfd7df9a0d76fedb2c740a1442b2d511dafc5ff59441f2845edcc95c5632426a169a0f94fbf0cafb230be41f58d0f5a725a94f3da262239acf3bb10a034ad0fbc32a921d936067df826c0d14df9db148632021e21f503581063da8316e4adbfea8b173b2d922d84743bbd43c2a767e49f4e6732a93aaedfc4faa8a1ff8f53657168f314134b267f17e083db817c514d39959f54e8fc2de056f15ce34cd47c0398673fccd4b6a4d526b6d9a747113072090805936ed6e7e0e830674c4f13fa5459460ae46f8a8003d8a18cd3a2482933fee3c283d635568f421d4c77c4cd89c5672427e936003effb7b5cf10e4cd2feeee1b5171993811a49425ce633973b8ac41d6458b6a9676b50d49143dcdbf312d80df71d08de62fb42988ee8299b8bfdac18c6210d137ede295156c9da1b95a2a7e3e17ee87613b21ccfe3b1948b9893fe73a5af9d5c06e786317bec02ae026296049221e902e11563b6c04fd90485790a7770f888b674e6c268e28f2be5f8458fd1b8e5546ce160d86783f11994b49994ca280a6fd2cd1dc3f50c0504d0411ecad0adf711c689be1fcfbd95772cfaed7176fb504dcb9334c691524ec8cc79dc7b67992abef15729ea61f7043c97d1a3501975d183b346a05b9ee2ac254a9615e72a267c9bd99997346f3d3aab8b20a58d03c02fc1d5c9d3fd360b62cec45fdf7140aa9b4a4cbd2b6a2f2d066d29f96b722d44968a6a5d590608fb5330d7e4da44fd00c08a3218a477721864d81eefaed4031b42ac42ed36fde3eb687fe3f36224b7597bf01d9b37ccffb56a06dfded120b6fdc2b14c2a8c74a6a09cba5e61f132a6112aaa0e1252325ed61fae029d1f3f6f938c631402024f6429aab5aeff391a994306b6d8017476a020c17f98be16ac1e4292e28832e413c1b809f37617fbca59eb02184398fec3cd43cb500f536a0c7bbe178f637675358d8bb3992233aac0db93c630daa2dcca8b57f0fd7a064277bd284b982d98861ddca0fb594a0e81fe989ef111cb7eb6c0cb64be87ed8e0c507cbce392341e23c01c767df46603157dbf4de334a4b8561d317432ac62ca9809984605690b224bd46e7fd78a7a9f13e000e42190efd103593967de0fd5ed6869fe3de2faaa527caa5d2edfaa4631348cf97c46ebc0b5e646153bce09b66b175a93b79d4f93fac6a968271e0a5679097e3bd4e1c09b367afd7402c03c61c9349e4d1ac23c180fe414575edde93893952d094374f84976d74c1f24e3b3bff1dc3dac1d34e2bc476e3d288928851e72d5cf600066c55e42f097272e0dc51feaf80deb5499fe2dcb27b33852eb76e8e8ade2c359250b749c3660e45e66065c6f72f8f71cfa2a521a0f48d92e7440601c4058e5a9bd20160b65d0f1b33bfa264e1e879c6ecc106b407b009df5dbe0bed77a7fbe4d1cb16b44e83a97c8fc3e271b133bd043cc0f7f3b2fa9b232a194c8f506203d68f54426cbe3a947f3f74a71473b8f952c9e86f43ada6490a1a87c3ffa1b8f6dadc73d94ff1260d8a52fdbc2ae17580f65d6119b5ce93626ebfee4e8a349949c5dc82db7d0da4202278d35360f55b971450a45ac97253da0f078f313250e427e2efd3d5266bcb7b1a81f456559d66b3c7b7db99b6057318f738d923c1c677c7d6cba126667c57bbc26c8a53fb93a319b3ac771cc87b0864c8894e2fb6ba996a6e8f18527e0b7fa25d5e3c18a58ce0e1e72bc80102949bec71bed45719ab00c5b9aaaded51a7621963af3505d225b238d46bf8f34f016a81169b1e50e0ec357ccfe8adaecaaf259b8deee36ee4f2e5f955ee6512a7a4495d30a29d8f477b0b3d42551168c9006c542098a55b1128edaebbb1bdd6f5684d95fffa4a852a6246239c57339fb35f5d8d5e23c287e8b6cd74f94d2f830960dd0d1f22e560eaa8ba30adba50420bd3504bd08e52e318f04f232d4d6f54af7b61170a6f79b26df1f17ee3f393c75da9a2ce882fc56229807304cb7b447049416961c58e0c3f6c368696969b03b2b8e6b469e7810ce2ed00512b2f203568a88c95f951f4f6fee47323469be4d81190e4982677632221761b2d02a9abaebae8bd9e02bfcd332b77a5741d27b56477e13b3faebdbf67dad2e3857b3b9d0</script>\n  <div class=\"hbe hbe-content\">\n    <div class=\"hbe hbe-input hbe-input-default\">\n      <input class=\"hbe hbe-input-field hbe-input-field-default\" type=\"password\" id=\"hbePass\">\n      <label class=\"hbe hbe-input-label hbe-input-label-default\" for=\"hbePass\">\n        <span class=\"hbe hbe-input-label-content hbe-input-label-content-default\">Hey, password is required here.</span>\n      </label>\n    </div>\n  </div>\n</div>\n<script data-pjax src=\"/lib/hbe.js\"></script><link href=\"/css/hbe.style.css\" rel=\"stylesheet\" type=\"text/css\">","tags":["紫鲸"]},{"title":"紫色的风铃草","url":"/2023/08/11/%E7%B4%AB%E8%89%B2%E7%9A%84%E9%A3%8E%E9%93%83%E8%8D%89/","content":"<p>女子轻盈的长裙摆，</p>\n<p>恰似阳春三月风；</p>\n<p>穿越闹市宽广道，</p>\n<p>越过原野无垠空，</p>\n<p>又在那温软海滨边，</p>\n<p>翩跹起舞，悠然翻涌。</p>\n<p>绵延的画面如诗卷，</p>\n<p>映现春山绿意浓，</p>\n<p>绽放春花笑颜灿，</p>\n<p>伴随春鸟歌声融；</p>\n<p>在春风之手抚弄下，</p>\n<p>画卷徐徐开，景致生动中。</p>\n<p>翩翩彩蝶追随戏，</p>\n<p>点缀生机盎然图；</p>\n<p>遗憾的是，在这幅画中，</p>\n<p>尚未觅得我踪影处。</p>\n<p>但我心向往化作那，</p>\n<p>一株紫裳风铃草；</p>\n<p>唯愿栖息在你独享的春天里，</p>\n<p>在你明亮如镜的眼眸深处，</p>\n<p>随风轻轻摇曳，述说柔情无数。</p>\n","tags":["小胡的小文"]},{"title":"铃铃铃","url":"/2023/08/15/%E9%93%83%E9%93%83%E9%93%83/","content":"<p> 一只蜻蜓栖息于荷花之上，或是刻意为之的雅致，亦或是无意间的动人美景。若非那日你抬头凝视，又怎会察觉我脸颊悄然泛起的红云？</p>\n<p>                                                            二</p>\n<p>                倾注深情于深深伤痕之中，这需真诚与无畏并存。</p>\n<p>每一道自脸颊滚落的泪珠，都承载着一段哀婉动人的篇章；每一朵傲然绽放的花朵，都在诉说着一则震撼人心的传奇！</p>\n<p>                                                              三</p>\n<p>                                            长亭绵延，短亭亦相随。</p>\n<p>                在长亭短亭间，你离我而去，同时也带走了我心中的眷恋。</p>\n<p> 自那个飞鸟漫天的黄昏后，我的书案不再有茶香弥漫，枕畔不再有诗意流淌，唇齿间也不再回荡歌声……</p>\n<p>                鸟儿，是否如同阳光在天空的倒影？原来你离去时，连同阳光也一同带走。如今，阳光的影子洒满我的双眸。</p>\n<p>                                                               四</p>\n<p>                        我曾想捕捉那些飞翔的鸟儿，将它们置于笼中。</p>\n<p>                            我不希冀生活被光明遮蔽的阴翳填满！</p>\n<p>                然而，我又怎忍心伤害那些自由的生灵？我究竟该如何抉择？</p>\n<p>            我依旧在花丛草地间安然入梦，仍旧吟唱着我那些纯真无暇的抒情诗篇。</p>\n<p>                                                         不知你怎样？</p>\n<p>                                                                五</p>\n<p>            你或许无法触及那些翱翔的鸟儿，毕竟，你是太阳之女啊！</p>\n<p>        你的笑声犹如一串悦耳的风铃，的确，多么欢快动听的风铃之声！</p>\n<p>        这美妙的风铃，不染丝毫哀愁，不带任何悲泣。能否再次为我奏响它的旋律？我热爱你那清澈纯净的声音，真的。</p>\n<p>                    倘若我的生命能化作一串风铃，我愿如此！</p>\n<p>                                                                六</p>\n<p>                            整个炎夏，我沉浸在一本描绘青春的小说中。</p>\n<p>                                作者？正是那位长发齐腰的活泼女孩！</p>\n<p>                她的笔触精彩绝伦，让每一天都充满了浪漫与活力的气息！</p>\n<p>                你才读了十几页？继续品读下去吧，这是一部非常优秀的作品。</p>\n<p>                                                                   七</p>\n<p>                                            岁月的尽头将会是什么模样？</p>\n<p>                                   风铃轻响，铃铃、铃铃铃、铃铃、铃铃铃……</p>\n","tags":["小胡的小文"]},{"title":"青铜葵花","url":"/2023/08/04/%E9%9D%92%E9%93%9C%E8%91%B5%E8%8A%B1/","content":"<p>        我坐在椅子上，感受着阳光的温暖，随手拿起了一本书，静静的阅读了起来。</p>\n<p>        这本书叫做《青铜葵花》，是曹文轩写的一本亲情小说。这本书主要讲了一个城市小女孩葵花和乡下小男孩青铜之间的故事。</p>\n<p>        青铜五岁的时候，屋子着了火，青铜看见了大火，被吓坏了，从此他就变成了一个哑巴。葵花是一个漂亮聪明的孩子，可她也是一个不幸的孩子。她的妈妈在她三岁时就离开了她，她的爸爸因为意外溺水也离开了她。她没有了爸爸妈妈，青铜一家领养了她。日子过得越来越好，城里的人把葵花接走了。葵花走后，青铜每天都在河边等着葵花回来。终于有一天，葵花回来了。青铜看见了葵花，兴奋地向她跑去，嘴里竟然还喊出了一声葵花。</p>\n<p>        故事结束了，但在故事中，青铜为葵花所做的一切都让我们感动。在家里决定只能让一人上学时，青铜偷偷地换掉杏子让葵花可以上学。在葵花要写作业但没有灯油时，青铜在南瓜花里放进了萤火虫给葵花照明。在学校举办节目而葵花缺少一条项链时，青铜把冰凌串成项链给葵花戴在身上，项链在阳光的照射下，一闪一闪的，美极了……</p>\n<p>            每一个时代的人，都会有每一个时代的人的痛苦 ，痛苦绝不是今天的少年才有的。如果少年时就有一种对待痛苦的风度，那么长大时才可能成为一个强者。</p>\n<p>            在书的最后，我读到了罗曼•罗兰的一段话：我们应该正视痛苦，尊重痛苦！欢乐固然值得赞颂，痛苦又何尝不值得赞颂!这两位是姊妹，而且都是圣者。她们锻炼人类开展伟大的心魄。她们是力，是生，是神 。凡是不能兼爱与痛苦的人，便是既不爱欢乐，亦不爱痛苦。凡能体味她们的，方懂得人生的价值和离开人生的甜蜜。我想《青铜葵花》告诉我的意思，应该就这一段话。</p>\n","tags":["小胡的小文"]},{"title":"胡哲涵名言目录","url":"/2023/08/31/%E8%83%A1%E5%93%B2%E6%B6%B5%E5%90%8D%E8%A8%80%E7%9B%AE%E5%BD%95/","content":"<p>趁时光仍未忘记我之时，赶紧记下来。</p>\n<span id=\"more\"></span>\n<p>不用因为没看到晚霞愁眉苦脸，以后还会有。———《紫鲸 陆(别名风山篇第2章)》胡哲涵 著<br>街道上的灯光是纸上跃动的墨水。———胡哲涵作文《晚上的重庆》原稿因被撕破目前只剩残缺的三分之一。<br>所有人的名字就像时间这条大桥上的一个过客，他记不得。———我在知乎关于人生话题下的回答。<br>鸟不会在意时间，因为时间也不会在意它———《紫鲸 伍(别名紫色的鸟儿)》 胡哲涵 著</p>\n"}]